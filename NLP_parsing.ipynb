{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-02c8ca83e419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuggest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mlp_001.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mylittlepony'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "from pattern.en import suggest\n",
    "filename = \"mlp_001.txt\"\n",
    "field = 'mylittlepony'\n",
    "filepath = 'data/{field}/{name}'.format(field=field,name=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----------by DM-----------\n",
    "\n",
    "#input : word, output : word\n",
    "\n",
    "#---------------------\n",
    "\n",
    "\n",
    "\n",
    "#...제외 3개이상 알파벳 반복 -> 2개\n",
    "def three2two(word):\n",
    "    pattern = re.compile(r'([^\\.]+)\\1{2,}')\n",
    "    return pattern.sub(r'\\1\\1', word)\n",
    "\n",
    "# word -> word ('helllloooo' -> 'hello')\n",
    "def correct_lengthen(word):\n",
    "    short_word = three2two(word)\n",
    "    if short_word != word:\n",
    "        p_word = suggest(short_word) #(가장 유사한 단어, 확률) tuples\n",
    "        short_word = p_word[0][0] #제일 높은 확률의 단어 (limitation : Nnnn -> Anna)\n",
    "        #print(short_word)\n",
    "    return short_word\n",
    "\n",
    "#---------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokens =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "\n",
    "#input : chunk\n",
    "#output : chunk without speaker \n",
    "#ex : \"Narrator : Once upon a time,,...\" -> \"Once upon a time...\"\n",
    "def parse_lv1(chunk):\n",
    "    newchunk = ''.join(chunk.split(':')[1:])\n",
    "    return newchunk\n",
    "#input : chunk without speaker \n",
    "#output : chunk without speker/지시문 \n",
    "#ex : \"[seriously] Once upon a time,,...\" -> \"Once upon a time...\"\n",
    "regex = re.compile(r'\\[.+\\]')\n",
    "def parse_lv3(chunk):\n",
    "    return regex.sub('',chunk)\n",
    "#input : chunk without speker/지시문 \n",
    "#output : chuck without speark/지시문 r'-*'\n",
    "#ex : \"H--i\" -> \"Hi\"\n",
    "def parse_lv4(chunk):\n",
    "    tokens = []\n",
    "    for token in chunk.split():\n",
    "        if '-' in token:\n",
    "            if token in words.words():# mother-in-law -> should be accepted\n",
    "                newtoken = [token]\n",
    "            elif '-' in token: #else case\n",
    "                newtoken = token.replace('-',' ').split() # basically split the '-' \n",
    "                if ''.join(newtoken) in words.words():    # Ex-cuseme -> excusme case\n",
    "                    \n",
    "                    newtoken = [''.join(newtoken)]\n",
    "        else:\n",
    "            newtoken = [token]\n",
    "        tokens+=newtoken\n",
    "    return ' '.join(tokens)\n",
    "#------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input : string\n",
    "#output : boolean\n",
    "#description : check whether string contains alphabet.\n",
    "def alphabet(s):\n",
    "    for c in s:\n",
    "        if (c>='0' and c<='9'):    \n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#input : string\n",
    "#output : boolen\n",
    "#description : check whether string's first letter is capital letter.\n",
    "def checkfirst(s):\n",
    "    return (s[0]==s[0].upper() and alphabet(s))\n",
    "\n",
    "#input : list of 덩어리\n",
    "#output : list of 단어\n",
    "#description : 겹치는 단어 제거\n",
    "def remove_prop(lst):\n",
    "    result=[]\n",
    "    prop=[]\n",
    "    for e in lst:\n",
    "        delimiters = \".\", \"!\", \"?\", \"\\n\"\n",
    "        regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "        tmp = re.split(regexPattern, e)\n",
    "        tmp = list(filter(None, tmp))\n",
    "        \n",
    "        for t in tmp:\n",
    "            deli = \",\", \" \"\n",
    "            reg = \"|\".join(map(re.escape, deli))\n",
    "            ss=re.split(reg,t.strip())\n",
    "            ss=list(filter(None, ss))\n",
    "            #ss=t.strip().split()\n",
    "            result=result+ss\n",
    "            S=ss[1:]\n",
    "            for s in S:\n",
    "                if(checkfirst(s) and (not s in prop)):\n",
    "                    prop.append(s)\n",
    "\n",
    "    result = list(filter(lambda a: not a in prop, result))\n",
    "    return result\n",
    "\n",
    "\n",
    "# result=remove_prop(lst)\n",
    "# print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input : filepath,filename,field; ex) data/{field}/{filename} -> data/mylittlepony/mlp_001.txt\n",
    "#output : tokens = [word,word,word,...,word]\n",
    "def parse(filepath,filename,field):\n",
    "    #regex = re.compile(r'\\[.+\\]')\n",
    "    chunks =[]\n",
    "    with open(filepath,'r') as f:\n",
    "        \n",
    "        for chunk in f: # 덩어리 기준\n",
    "            chunk = chunk.strip()\n",
    "            #1 : 지시문, 화자는 제외\n",
    "            #1-1 화자 제거\n",
    "            chunk = parse_lv1(chunk)\n",
    "            #1-2 지시문 제거\n",
    "            chunk = parse_lv3(chunk)\n",
    "            #2 -와 -- 제거\n",
    "            chunk = parse_lv4(chunk)\n",
    "            # lengthenword correcting\n",
    "            #correct_lengthen(word)\n",
    "            newchunk = []\n",
    "            for word in chunk.split():\n",
    "                newchunk.append(correct_lengthen(word))\n",
    "            newchunk = ' '.join(newchunk)\n",
    "            #remove proper noun\n",
    "            chunks.append(newchunk)\n",
    "        wordset = remove_prop(newchunk)\n",
    "    return wordset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suggest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5556007b9787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-46f6c90cf74b>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(filepath, filename, field)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnewchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mnewchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_lengthen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mnewchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#remove proper noun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-8ff220cfdcd5>\u001b[0m in \u001b[0;36mcorrect_lengthen\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mshort_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthree2two\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshort_word\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mp_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_word\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(가장 유사한 단어, 확률) tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mshort_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#제일 높은 확률의 단어 (limitation : Nnnn -> Anna)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(short_word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'suggest' is not defined"
     ]
    }
   ],
   "source": [
    "tk = parse(filepath,filename,field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Once upon a time, in the magical land of Equestria, there were two regal sisters who ruled together and created harmony for all the land. To do this, the eldest used her unicorn powers to raise the sun at dawn; the younger brought out the moon to begin the night. Thus, the two sisters maintained balance for their kingdom and their subjects, all the different types of ponies. But as time went on, the younger sister became resentful. The ponies relished and played in the day her elder sister brought forth, but shunned and slept through her beautiful night. One fateful day, the younger unicorn refused to lower the moon to make way for the dawn. The elder sister tried to reason with her, but the bitterness in the young one's heart had transformed her into a wicked mare of darkness Nightmare Moon.\",\n",
       " '',\n",
       " 'She vowed that she would shroud the land in eternal night. Reluctantly, the elder sister harnessed the most powerful magic known to ponydom the Elements of Harmony. Using the magic of the Elements of Harmony, she defeated her younger sister, and banished her permanently in the moon. The elder sister took on responsibility for both...',\n",
       " '...sun and moon...',\n",
       " \"...and harmony has been maintained in Equestria for generations since. Hmm... Elements of Harmony. I know I've heard of those before... but where?\",\n",
       " '',\n",
       " 'There you are, Twilight! Moon Dancer is having a little get together in the west castle courtyard. You wanna come?',\n",
       " \"Oh, sorry, girls... I've got a lot of studying to catch up on.\",\n",
       " \"Does that pony do anything except study? I think she's more interested in books than friends.\",\n",
       " \"I know I've heard of the Elements of Harmony.\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stopwords removing using NLTK I, Mr. / I'll I've  /  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
